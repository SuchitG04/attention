{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.204979Z",
     "start_time": "2024-04-22T14:31:42.576491Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0d8887fcdcfa8b",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "- create a vocab of sorts for demonstration\n",
    "- consider an example sentence and tokenize it (using the vocab)\n",
    "- create token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd2bd5f628e6afef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.209684Z",
     "start_time": "2024-04-22T14:31:44.206225Z"
    }
   },
   "outputs": [],
   "source": [
    "word_list_str = \"the and of to a in is it you that he was for on are with as I his they at be this have from or one had by word but not what all were we when your can said there use an each which she do how their if will up other about out many then them these so some her would make like him into time has look two more write go see number no way could people my than first water been call who oil its now find long down day did get come made may part\"\n",
    "\n",
    "word_list = word_list_str.split()\n",
    "rev_vocab = dict(enumerate(word_list))\n",
    "\n",
    "# map words to numbers\n",
    "vocab = dict(zip(rev_vocab.values(), rev_vocab.keys()))\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "dim_tok_emb = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "572df015cb17fd50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.213670Z",
     "start_time": "2024-04-22T14:31:44.211427Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence = \"the number was long\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d850eb434f31532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.222744Z",
     "start_time": "2024-04-22T14:31:44.215181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(sentence: str) -> torch.Tensor:\n",
    "    tokenized = []\n",
    "    for word in sentence.split():\n",
    "        tokenized.append(vocab[word])\n",
    "        \n",
    "    return torch.tensor(tokenized)\n",
    "\n",
    "tokenized = tokenize(sentence); tokenized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0148bda860898bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:37:28.835526Z",
     "start_time": "2024-04-22T14:37:28.829232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 75, 11, 91])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3fd8e301c6240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.229663Z",
     "start_time": "2024-04-22T14:31:44.225751Z"
    }
   },
   "outputs": [],
   "source": [
    "# here, we will use embedding of size 120 for no particular reason\n",
    "embed = nn.Embedding(vocab_size, dim_tok_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad2b43a9b7606d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.238116Z",
     "start_time": "2024-04-22T14:31:44.234334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 120])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings = embed(tokenized).detach(); sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42ffe3a166da208",
   "metadata": {},
   "source": [
    "## TODO - single attention head\n",
    "\n",
    "- create W_q, W_k, W_v\n",
    "- try out the entire process for a single token embedding\n",
    "- create the attention pattern initially having just q.k\n",
    "- then apply softmax column-wise (imagine the attention pattern having keys spread down each row in every column and queries spread across each column down the rows)\n",
    "\n",
    "Attention formula: $\\text{Attention}(Q,K,V)=\\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baa7435da377bd6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.242175Z",
     "start_time": "2024-04-22T14:31:44.239069Z"
    }
   },
   "outputs": [],
   "source": [
    "# weight matrices\n",
    "\n",
    "# dim of W_q is less than that of tok_emb. here, let's consider 12 as the dim\n",
    "# how is W_q and W_k used? W_q is mmulted with tok_emb to get a new representation in the key-query space (12 dim)\n",
    "dim_key_query = 12\n",
    "W_q = torch.randn(dim_tok_emb, dim_key_query)\n",
    "W_k = torch.randn(dim_tok_emb, dim_key_query)\n",
    "\n",
    "# W_v can be implemented using two low rank matrices as well, but we'll do it using a single matrix here.\n",
    "# how is W_v used? W_v is mmulted with tok_emb to get a new representation of the original token embedding in the embedding space itself (not entirely sure about this, but this is the implementation in the 3b1b vid)\n",
    "W_v = torch.randn(dim_tok_emb, dim_tok_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe58a55b38aacb1f",
   "metadata": {},
   "source": [
    "W_q & W_k -> 120 x 12 <br>\n",
    "W_v -> 120 x 120\n",
    "\n",
    "k -> 12 <br>\n",
    "q -> 12 <br>\n",
    "v -> 12 <br>\n",
    "\n",
    "tok_emb -> 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba71b8b684bdd249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.249675Z",
     "start_time": "2024-04-22T14:31:44.243704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 12])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5f0b53e92d40c0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.256146Z",
     "start_time": "2024-04-22T14:31:44.253131Z"
    }
   },
   "outputs": [],
   "source": [
    "x_1 = sentence_embeddings[0]\n",
    "q_1 = x_1 @ W_q\n",
    "k_1 = x_1 @ W_k\n",
    "v_1 = x_1 @ W_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "522ab8d61cb49a62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.260365Z",
     "start_time": "2024-04-22T14:31:44.257198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e98e89137d7601fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.265508Z",
     "start_time": "2024-04-22T14:31:44.261349Z"
    }
   },
   "outputs": [],
   "source": [
    "qk_1 = torch.dot(q_1, k_1) / dim_key_query**0.5\n",
    "neg_infs = torch.tensor([-torch.inf] * (sentence_embeddings.shape[0] - 1))\n",
    "col_temp = torch.cat([torch.tensor([qk_1]), neg_infs])\n",
    "col_norm = torch.softmax(col_temp, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a9d424710f6ee11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.272231Z",
     "start_time": "2024-04-22T14:31:44.267669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4]), torch.Size([120]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_norm.shape, v_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a292d38e713940f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.277495Z",
     "start_time": "2024-04-22T14:31:44.273601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltaE = (col_norm.unsqueeze(-1) * v_1).sum(dim=0); deltaE.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b7523f829535390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.282712Z",
     "start_time": "2024-04-22T14:31:44.278639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this indicates that the above operation worked correctly because we know that col_norm has values [1, 0, 0, 0]\n",
    "# and computing the weighted sum of v_1 with col_norm should just give v_1\n",
    "torch.equal(deltaE, v_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6392ad9e8153a245",
   "metadata": {},
   "source": [
    "### Repeat the above process for the entire sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ce9fdb6fca760ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.290412Z",
     "start_time": "2024-04-22T14:31:44.284317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 120]), torch.Size([120, 12]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape, W_q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ca05fea4742501e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.294722Z",
     "start_time": "2024-04-22T14:31:44.291559Z"
    }
   },
   "outputs": [],
   "source": [
    "x = sentence_embeddings\n",
    "q = x @ W_q\n",
    "k = x @ W_k\n",
    "v = x @ W_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aba9033111b4d22e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.300417Z",
     "start_time": "2024-04-22T14:31:44.296114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 12]), torch.Size([4, 12]), torch.Size([4, 120]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cd19f79e0eb1077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.306175Z",
     "start_time": "2024-04-22T14:31:44.302005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c19a9870acf0e4c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.311316Z",
     "start_time": "2024-04-22T14:31:44.307351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(q @ k.T, (k@q.T).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "260dd94dcf3124f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.316016Z",
     "start_time": "2024-04-22T14:31:44.312203Z"
    }
   },
   "outputs": [],
   "source": [
    "# care has to be taken to see if k @ q.T or q @ k.T has to be used here\n",
    "# the former implementation is more appropriate purely going by what is shown by 3b1b\n",
    "qk = (k @ q.T) / dim_key_query**0.5\n",
    "mask = torch.eq(torch.triu(qk), 0)\n",
    "qk[mask] = -torch.inf\n",
    "attn_pattern = torch.softmax(qk, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999bcbb169b0b953",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "- compute deltaE values from the attention pattern\n",
    "- add them to the original embeddings\n",
    "- unlike before where the usage of certain variable names makes it appear like the v values are being used column wise, we must use it such it each key has a different v value (each row has a different v value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "769a5cff9ceeebab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.323272Z",
     "start_time": "2024-04-22T14:31:44.316951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 4]), torch.Size([4, 120]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_pattern.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "479725e4c828abb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.331913Z",
     "start_time": "2024-04-22T14:31:44.324669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal((attn_pattern.T @ v), (v.T @ attn_pattern).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c5ac116e23c0ab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.337534Z",
     "start_time": "2024-04-22T14:31:44.333238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 120])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltaE = (attn_pattern.T @ v); deltaE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78582402ee398857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.343050Z",
     "start_time": "2024-04-22T14:31:44.338903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deltaE1 is the change to be applied to the first token embedding.\n",
    "deltaE1 = (attn_pattern[:, 1].unsqueeze(-1) * v).sum(dim=0); deltaE1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af1e5666e06d0223",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.347679Z",
     "start_time": "2024-04-22T14:31:44.344329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(deltaE[1], deltaE1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f6dcf15a1de76c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.379295Z",
     "start_time": "2024-04-22T14:31:44.372857Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 120])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import attention\n",
    "d_in, d_out_kq, d_out_v = 120, 12, 120\n",
    "\n",
    "s = attention.SelfAttention(d_in, d_out_kq, d_out_v)\n",
    "s(sentence_embeddings).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "972f685b54b80e05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:31:44.584016Z",
     "start_time": "2024-04-22T14:31:44.380282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 120])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = attention.MultiHeadAttention(120, 12, 120, 4)\n",
    "m(sentence_embeddings).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e7e26f3b5d3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e134824-2d5e-48bd-a9be-030c3d6ecd36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
